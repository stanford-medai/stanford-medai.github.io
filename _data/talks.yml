# - speaker:
#   type: upcoming (or previous)
#   date:
#   title:
#   abstract:
#   bio:
#   livestream:
#   recording:

#### Previous talks: make sure order is right. Can just replace upcoming with previous in place

- speaker: Amirata Ghorbani
  institution: Stanford University
  type: previous
  date: 4/1/21
  title: Equitable Valuation of Data
  abstract: As data becomes the fuel driving technological and economic growth, a fundamental challenge is how to quantify the value of data in algorithmic predictions and decisions. For example, in healthcare and consumer markets, it has been suggested that individuals should be compensated for the data that they generate, but it is not clear what is an equitable valuation for individual data. In this talk, we discuss a principled framework to address data valuation in the context of supervised machine learning. Given a learning algorithm trained on a number of data points to produce a predictor, we propose data Shapley as a metric to quantify the value of each training datum to the predictor performance. Data Shapley value uniquely satisfies several natural properties of equitable data valuation. We introduce Monte Carlo and gradient-based methods to efficiently estimate data Shapley values in practical settings where complex learning algorithms, including neural networks, are trained on large datasets. We then briefly discuss the notion of distributional Shapley, where the value of a point is defined in the context of underlying data distribution.
  bio: <a href="https://www.amiratag.com/" target="_blank">Amirata Ghorbani</a> is a fifth year PhD student at Stanford University advised by James Zou. He primarily works on different problems in machine learning such as research on equitable methods for data valuation, algorithms to interpret machine learning models, ways to make existing ML predictors fairer, and creating ML systems for healthcare applications such as cardiology and dermatology. He has also worked as a research intern in Google Brain, Google Brain Medical, and Salesforce Research.
  recording: https://youtu.be/TzbFPsJ3o7U

- speaker: Michael Zhang
  institution: Stanford University
  type: previous
  date: 4/8/21
  title: Federated Learning with FOMO for Personalized Training and Deployment
  abstract: Federated learning (FL) is an exciting and relatively new deep learning framework that canonically trains a single global model across decentralized local datasets maintained by participating clients. Accordingly with respect to making deep learning more deployable, FL is particularly promising in real world settings where technological or privacy constraints prevent individual data from being aggregated together. However, one model may not always be optimal for all participating clients. From healthcare to recommendation systems, we would ideally like to learn and deliver a personalized model for each participating client, as data may not be identically distributed from one client to another. This problem is emphasized when we consider how we might deploy FL in practice, where individual clients may only choose to federate if they can guarantee a benefit from the model produced at the end.<br><br>In this talk, I will present some recent work on one solution, called FedFomo, where each client effectively only federates with other relevant clients to obtain stronger personalization. First we will review federated learning as a machine learning framework, emphasizing the motivations behind personalized FL. I will then go into the origin story of FedFomo's name, highlighting a simple yet effective approach based both on the "fear of missing out" and "first order model optimization". In tandem, these ideas describe how FedFomo can efficiently figure out how much each client can benefit from another's locally trained model, and then use these values to calculate optimal federated models for each client. Critically, this does not assume knowledge of any underlying data distributions or client similarities, as this information is often not known apriori. Finally, I will describe recent empirical results on FedFomo's promising performance on a variety of federated settings, datasets, and degrees of local data heterogeneity, leading to wider discussion on the future directions and impact of federated learning and distributed machine learning, when personalization is in the picture.
  bio: Michael Zhang is a Computer Science PhD Student at Stanford, currently working with Chris Ré and Chelsea Finn. He is broadly interested in making machine learning more deployable and reliable in the "real world", especially through the lenses of improving model robustness and personalization to distribution shifts and new tasks, as well as developing new systems that enable collaborative machine learning and/or learning with less labels.
  livestream: https://www.youtube.com/channel/UCOkkljs06NPPkjNysCdQV4w
  recording: https://www.youtube.com/watch?v=svBDaT4IY4A

- speaker: Jason Fries
  institution: Stanford University
  type: previous
  date: 4/15/21
  livestream: https://www.youtube.com/channel/UCOkkljs06NPPkjNysCdQV4w
  title: Weakly Supervised Learning in Medicine (Better Living through Programmatic Supervision)
  abstract: The high cost of building labeled training sets is one of the largest barriers to using supervised machine learning in medicine. Privacy concerns create additional challenges to sharing training data for modalities like patient notes, making it difficult to train state-of-the-art NLP tools for analyzing electronic health records. The COVID-19 pandemic underscores the need for faster, more systematic methods of curating and sharing training data. One promising approach is weakly supervised learning, where low cost and often noisy label sources are combined to programmatically generate labeled training data for commodity deep learning architectures such as BERT. Programmatic labeling takes a data-centric view of machine learning and provides many of the same practical benefits as software development, including better consistency, inspectability, and creating higher-level abstractions for experts to inject domain knowledge into machine learning models.<br><br>In this talk I outline our new framework for weakly supervised clinical entity recognition, Trove, which builds training data by combining multiple public medical ontologies and other imperfect label sources. Instead of manually labeling data, in Trove annotators focus on defining labelers using ontology-based properties like semantic types as well as optional task-specific rules. On four named entity benchmark tasks, Trove approaches the performance of models trained using hand-labeled data. However unlike hand-labeled data, our labelers can be shared and modified without compromising patient privacy.
  bio: Jason Fries (<a href="http://web.stanford.edu/~jfries/" target="_blank">http://web.stanford.edu/~jfries/</a>) is a Research Scientist at Stanford University working with Professor Nigam Shah at the Center for Biomedical Informatics Research. He previously completed his postdoc with Professors Chris Ré and Scott Delp as part of Stanford's Mobilize Center. He received his PhD in computer science from the University of Iowa, where he studied computational epidemiology and NLP methods for syndromic surveillance. His recent research explores weakly supervised and few-shot learning in medicine, with a focus on methods for incorporating domain knowledge into the training of machine learning models. 
  recording: https://www.youtube.com/watch?v=EcvLqmeD7SE

- speaker: Pradeeban Kathiravelu
  institution: Emory University
  type: previous
  date: 4/22/21
  livestream: https://www.youtube.com/channel/UCOkkljs06NPPkjNysCdQV4w
  title: Understanding Scanner Utilization with Real-Time DICOM Metadata Extraction
  abstract: Understanding system performance metrics ensures better utilization of the radiology resources with more targeted interventions. The images produced by radiology scanners typically follow the DICOM (Digital Imaging and Communications in Medicine) standard format. The DICOM images consist of textual metadata that can be used to calculate key timing parameters, such as the exact study durations and scanner utilization. However, hospital networks lack the resources and capabilities to extract the metadata from the images quickly and automatically compute the scanner utilization properties. Thus, they resort to using data records from the Radiology Information Systems (RIS). However, data acquired from RIS are prone to human errors, rendering many derived key performance metrics inadequate and inaccurate. Hence, there is motivation to establish a real-time image transfer from the Picture Archiving and Communication Systems (PACS) to receive the DICOM images from the scanners to research clusters to conduct such metadata processing to evaluate scanner utilization metrics efficiently and quickly.<br><br>In this talk, we present Niffler (https://github.com/Emory-HITI/Niffler), an open-source DICOM Framework for Machine Learning Pipelines and Processing Workflows. Niffler analyzes the scanners' utilization as a real-time monitoring framework that retrieves radiology images into a research cluster using the DICOM networking protocol and then extracts and processes the metadata from the images. Niffler facilitates a better understanding of scanner utilization across a vast healthcare network by observing properties such as study duration, the interval between the encounters, and the series count of studies. Benchmarks against using the RIS data indicate that our proposed framework based on real-time PACS data estimates the scanner utilization more accurately. Our framework has been running stable and supporting several machine learning workflows for more than two years on our extensive healthcare network in pseudo-real-time. We further present how we use the Niffler framework for real-time and on-demand execution of machine learning (ML) pipelines on radiology images.
  bio: Pradeeban Kathiravelu is a postdoctoral researcher at the Department of Biomedical Informatics in Emory University. He has an Erasmus Mundus Joint Doctorate in Distributed Computing from Universidade de Lisboa (Lisbon, Portugal) and Université catholique de Louvain (Louvain-la-Neuve, Belgium). His research focus includes researching and developing latency-aware Software-Defined Systems and cloud-assisted networks for radiology workflows at the edge.
  recording: https://youtu.be/oiQAjfYc9Sc


- speaker: Joseph Cohen
  institution: Stanford University
  type: upcoming
  date: 4/29/21
  livestream: https://www.youtube.com/channel/UCOkkljs06NPPkjNysCdQV4w
  title: "Gifsplanation via Latent Shift: A Simple Autoencoder Approach to Counterfactual Generation for Chest X-rays"
  abstract: "Motivation: Traditional image attribution methods struggle to satisfactorily explain predictions of neural networks. Prediction explanation is important, especially in medical imaging, for avoiding the unintended consequences of deploying AI systems when false positive predictions can impact patient care. Thus, there is a pressing need to develop improved models for model explainability and introspection. <br>Specific problem: A new approach is to transform input images to increase or decrease features which cause the prediction. However, current approaches are difficult to implement as they are monolithic or rely on GANs. These hurdles prevent wide adoption.<br>Our approach: Given an arbitrary classifier, we propose a simple autoencoder and gradient update (Latent Shift) that can transform the latent representation of a specific input image to exaggerate or curtail the features used for prediction. We use this method to study chest X-ray classifiers and evaluate their performance. We conduct a reader study with two radiologists assessing 240 chest X-ray predictions to identify which ones are false positives (half are) using traditional attribution maps or our proposed method.<br>Results: We found low overlap with ground truth pathology masks for models with reasonably high accuracy. However, the results from our reader study indicate that these models are generally looking at the correct features.We also found that the Latent Shift explanation allows a user to have more confidence in true positive predictions compared to traditional approaches (0.15±0.95 in a 5 point scale with p=0.01) with only a small increase in false positive predictions (0.04±1.06 with p=0.57).<br>Project Page: https://mlmed.org/gifsplanation/ <br>Source code: https://github.com/mlmed/gifsplanation"
  bio: Joseph Paul Cohen is a researcher and pragmatic engineer. He currently focuses on the challenges in deploying AI tools in medicine specifically computer vision and genomics and is affiliated to Stanford AIMI. He maintains many open source projects including Chester the AI radiology assistant, TorchXRayVision, and BlindTool – a mobile vision aid app. He is the director of the Institute for Reproducible Research, a US non-profit which operates ShortScience.org and Academic Torrents.
  
- speaker: Angshuman Paul
  institution: NIH
  type: upcoming
  date: 5/6/21
  livestream: https://www.youtube.com/channel/UCOkkljs06NPPkjNysCdQV4w

- speaker: Xiaoyuan Guo
  institution: Emory University
  type: upcoming
  date: 5/13/21
  livestream: https://www.youtube.com/channel/UCOkkljs06NPPkjNysCdQV4w

- speaker: Sudarsan Sadasivuni
  institution: SUNY Buffalo
  type: upcoming
  date: 5/20/21
  livestream: https://www.youtube.com/channel/UCOkkljs06NPPkjNysCdQV4w

- speaker: Amara Tariq
  institution: Emory University
  type: upcoming
  date: 5/27/21
  livestream: https://www.youtube.com/channel/UCOkkljs06NPPkjNysCdQV4w

